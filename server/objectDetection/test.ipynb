{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a580a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load your model onto GPU\n",
    "model = YOLO('yolov8n.pt').to('cuda:0')\n",
    "\n",
    "# Start streaming + tracking\n",
    "stream = model.track(\n",
    "    source=r'D:\\self study\\0 - FYP\\Seatify\\server\\objectDetection\\assets\\video5.mp4',\n",
    "    tracker='bytetrack.yaml',\n",
    "    classes=[0, 56, 60],     # person, chair, dining table\n",
    "    persist=True,\n",
    "    show=False,              # we’ll show manually\n",
    "    save=True,\n",
    "    save_dir='my_outputs/',  # where annotated video is saved\n",
    "    stream=True,             # frame‐by‐frame generator\n",
    "    device='cuda:0'\n",
    ")\n",
    "\n",
    "# Define BGR colors for each label\n",
    "colors = {\n",
    "    'person':       (0,   0, 255),  # red\n",
    "    'chair':        (0, 255,   0),  # green\n",
    "    'dining table': (255, 0,   0)   # blue\n",
    "}\n",
    "\n",
    "for frame_idx, res in enumerate(stream):\n",
    "    frame = res.orig_img.copy()  # get the raw frame as a NumPy array\n",
    "\n",
    "    # If there are no detections, just display/skip\n",
    "    if not res.boxes or len(res.boxes.xyxy) == 0:\n",
    "        print(f\"Frame {frame_idx}: no detections\")\n",
    "    else:\n",
    "        print(f\"Frame {frame_idx}:\")\n",
    "        # iterate in parallel through each detection\n",
    "        xyxys     = res.boxes.xyxy.cpu().numpy()\n",
    "        confs     = res.boxes.conf.cpu().numpy()\n",
    "        cls_ids   = res.boxes.cls.cpu().numpy().astype(int)\n",
    "        track_ids = res.boxes.id.cpu().numpy().astype(int)\n",
    "\n",
    "        for (x1, y1, x2, y2), conf, cls_id, track_id in zip(xyxys, confs, cls_ids, track_ids):\n",
    "            label = res.names[cls_id]              # e.g. \"person\", \"chair\", \"dining table\"\n",
    "            color = colors.get(label, (255,255,255))  # white fallback\n",
    "\n",
    "            # draw box & text\n",
    "            cv2.rectangle(frame, (int(x1),int(y1)), (int(x2),int(y2)), color, 2)\n",
    "            text = f\"{label} {conf:.2f} ID:{track_id}\"\n",
    "            cv2.putText(frame, text, (int(x1), int(y1)-10),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
    "            print(f\"  → {label:12s} conf={conf:.2f}  box=[{int(x1)},{int(y1)},{int(x2)},{int(y2)}]  track_id={track_id}\")\n",
    "\n",
    "    # show the custom‐colored frame\n",
    "    cv2.imshow(\"Tracking (q to quit)\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
